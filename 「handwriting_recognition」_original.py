# -*- coding: utf-8 -*-
"""「handwriting_recognition」_Original

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SfDwPrVuN5gl13r0l_tG9-lQ2d0406CL

# 主題：手寫識別

**原作者:** [A_K_Nain](https://twitter.com/A_K_Nain), [Sayak Paul](https://twitter.com/RisingSayak)<br>
**組員:** <br>
A110223010 胡定捷<br>
A110223011 羅鈞元<br>
A110223019 陳乙慈<br>
A110223028 吳佳涓<br>
**描述:** 訓練具有可變長度序列的手寫識別模型。

## 介紹

This example shows how the [Captcha OCR](https://keras.io/examples/vision/captcha_ocr/)
example can be extended to the
[IAM Dataset](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database),
which has variable length ground-truth targets. Each sample in the dataset is an image of some
handwritten text, and its corresponding target is the string present in the image.
The IAM Dataset is widely used across many OCR benchmarks, so we hope this example can serve as a
good starting point for building OCR systems.

此範例展示了[驗證碼OCR](https://keras.io/examples/vision/captcha_ocr/)如何擴充套件到[IAM資料集](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database)，該資料集具有可變長度的地面真相目標。 資料集中的每個樣本都是一些手寫文字的影象，其相應的目標是影象中存在的字串。 IAM資料集廣泛用於許多OCR基準，因此我們希望這個例子可以作為構建OCR系統的良好起點。

## 數據採集
"""
'''
!wget -q https://git.io/J0fjL -O IAM_Words.zip #自動下載檔案
!unzip -qq IAM_Words.zip #解壓縮zip檔

!mkdir data #建立目錄
!mkdir data/words #建立目錄資料夾
!tar -xf IAM_Words/words.tgz -C data/words #解壓縮IAM_Words/words.tgz內的所有文件
!mv IAM_Words/words.txt data  #將文件重新命名或將文件移動到目錄中

"""Preview how the dataset is organized. Lines prepended by "#" are just metadata information.
預覽數據集的組織方式。以“#”開頭的行只是元數據信息。
"""

!head -20 data/words.txt #運行外部程序
'''
"""## 匯入模組"""

from tensorflow.keras.layers.experimental.preprocessing import StringLookup #引用StringLookup模組
from tensorflow import keras #引入keras模組

import matplotlib.pyplot as plt #引入視覺化模組
import tensorflow as tf #引入深度學習模組
import numpy as np #建立陣列模組
import os #引入os模組(與作業系統相關)

np.random.seed(42) #產生隨機整數的亂數
tf.random.set_seed(42) #設計全局隨機種子

"""## 數據集拆分"""

base_path = "data" #設定根路徑
words_list = [] #新單詞辭典

words = open(f"{base_path}/words.txt", "r").readlines() #開啟檔名(f"{base_path}/words.txt",設定檔案為唯獨).讀取所有行並返回列表
for line in words: #設定迴圈
    if line[0] == "#": #如果數值為#
        continue #跳出本次迴圈並進入下一圈
    if line.split(" ")[1] != "err":  #如果(切割空白後的值不等於err)
      # We don't need to deal with errored entries.
        words_list.append(line) #在列表末尾添加新的值(line)

len(words_list) #返回列表的長度

np.random.shuffle(words_list) #將列表元素重新洗牌

"""將數據集拆分成三個子集，比例為90:5:5(train:validation:test)。"""

split_idx = int(0.9 * len(words_list)) #取得列表的長度*0.9
train_samples = words_list[:split_idx] #設定train_sample的值為全部的9成
test_samples = words_list[split_idx:] #設定test_samples的值為剩下的1成

val_split_idx = int(0.5 * len(test_samples)) #取得列表的長度*0.5
validation_samples = test_samples[:val_split_idx] #設定validation_samples的值為test_samples中的5成
test_samples = test_samples[val_split_idx:] #設定test_samples為剩下的5成

assert len(words_list) == len(train_samples) + len(validation_samples) + len( #檢查word_list的值是train_samples+validation_samples+test_samples
    test_samples
)

print(f"Total training samples: {len(train_samples)}") #印出
print(f"Total validation samples: {len(validation_samples)}") #印出
print(f"Total test samples: {len(test_samples)}") #印出

"""## 數據輸入途徑

首先準備圖像路徑來開始構建數據輸入途徑。
"""

base_image_path = os.path.join(base_path, "words") #連接兩個路徑名稱


def get_image_paths_and_labels(samples): #定義一個函式 取得圖片的路徑和標籤
    paths = [] #設定paths為空陣列
    corrected_samples = [] #設定corrected_samples為空陣列
    for (i, file_line) in enumerate(samples): #使用迴圈將數據整合為索引序列
        line_split = file_line.strip() #移除字符串指定的字符()
        line_split = line_split.split(" ") #將line_split的空白切割

        # Each line split will have this format for the corresponding image:
        # part1/part1-part2/part1-part2-part3.png
        image_name = line_split[0] #設定image_name的名稱
        partI = image_name.split("-")[0] #設定partI為image_name切割-後的字符串
        partII = image_name.split("-")[1] #設定partII為image_name切割-後的字符串
        img_path = os.path.join( #連接多個路徑名稱{
            base_image_path, partI, partI + "-" + partII, image_name + ".png"
        ) #}
        if os.path.getsize(img_path): #如果有得到img_path的檔案大小
            paths.append(img_path) #在path的尾端新增img_path
            corrected_samples.append(file_line.split("\n")[0]) #在corrected_samples的尾端新增file_line切割\n的字符串
    return paths, corrected_samples #回傳paths, corrected_samples


train_img_paths, train_labels = get_image_paths_and_labels(train_samples) #設定train_img_paths, train_labels的值為取得的path和label
validation_img_paths, validation_labels = get_image_paths_and_labels(validation_samples) #設定validation_img_paths, validation_labels的值為get_image_paths_and_labels(validation_samples)
test_img_paths, test_labels = get_image_paths_and_labels(test_samples) #設定test_img_paths, test_labels的值為get_image_paths_and_labels(test_samples)

"""然後我們準備ground-truth labels。"""

# Find maximum length and the size of the vocabulary in the training data.
train_labels_cleaned = [] #設定train_labels_cleaned為空陣列
characters = set() #建立集合
max_len = 0 #設定最大長度

for label in train_labels: #設定迴圈
    label = label.split(" ")[-1].strip() #移除字符串頭尾(" ")
    for char in label: #設定迴圈
        characters.add(char)

    max_len = max(max_len, len(label))#最大長度=label的長度
    train_labels_cleaned.append(label)#空陣列加入label的內容

characters = sorted(list(characters))#排序characters

print("Maximum length: ", max_len)#印出
print("Vocab size: ", len(characters))#印出

# Check some label samples.
train_labels_cleaned[:10]

"""現在我們也清理驗證和測試標籤。"""

def clean_labels(labels): #自訂函式clean_labels 用來驗證和清理標籤
    cleaned_labels = []#設定空陣列
    for label in labels: #設定迴圈
        label = label.split(" ")[-1].strip() #依空格分割label 刪除首尾空格
        cleaned_labels.append(label)#處理好的label加入陣列
    return cleaned_labels#回傳處理好的標籤陣列


validation_labels_cleaned = clean_labels(validation_labels)#處理validation_labels
test_labels_cleaned = clean_labels(test_labels)#處理test_labels

"""### 構建字符詞彙表"""

AUTOTUNE = tf.data.AUTOTUNE#更好的載入資料

# Mapping characters to integers.
char_to_num = StringLookup(vocabulary=list(characters), mask_token=None)#將characters內的資料給予對應的索引編碼

# Mapping integers back to original characters.#把索引編碼對應回原資料
num_to_char = StringLookup(
    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True
)

"""### 調整圖像大小而不失真
為了將圖像大小調整為統一大小，因此執行調整大小以滿足以下條件：
* 縱橫比被保留。
* 圖像的內容不受影響。
"""

def distortion_free_resize(image, img_size): #自訂函式edistortion_free_resiz 用來縮放圖片
    w, h = img_size#變數 寬,高
    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)#preserve_aspect_ratio=True 按照長寬比縮放圖片

    # Check tha amount of padding needed to be done.
    pad_height = h - tf.shape(image)[0] #確定完成調整後的高
    pad_width = w - tf.shape(image)[1] #確定完成調整後的寬

    # Only necessary if you want to do same amount of padding on both sides.
    if pad_height % 2 != 0: #如果pad_height除2的餘數不等於0
        height = pad_height // 2 #height會等於pad_height除2取商(整數)
        pad_height_top = height + 1 #pad_height_top會等於height+1
        pad_height_bottom = height #pad_height_bottom等於height
    else: #如果pad_height除2的餘數等於0
        pad_height_top = pad_height_bottom = pad_height // 2 #pad_height_top會等於pad_height_bottom會等於pad_height除2並取商

    if pad_width % 2 != 0: #如果pad_width除2的餘數不等於0
        width = pad_width // 2 #width會等於pad_width除2取商(整數)
        pad_width_left = width + 1 #pad_width_left會等於width+1
        pad_width_right = width #pad_width_right等於width
    else: #如果pad_width除2的餘數等於0
        pad_width_left = pad_width_right = pad_width // 2 #pad_width_left會等於pad_width_right會等於pad_width除2並取商

    image = tf.pad( #將圖片照上面算出的數字填充(組合成單字){
        image,
        paddings=[
            [pad_height_top, pad_height_bottom],
            [pad_width_left, pad_width_right],
            [0, 0],
        ],
    )#}
    image = tf.transpose(image, perm=[1, 0, 2])#轉制多維陣列image
    image = tf.image.flip_left_right(image)#將圖片從左到右翻轉
    return image#回傳

"""如果我們只是簡單地調整大小，那麼圖像將如下所示：

![](https://i.imgur.com/eqq3s4N.png)

注意這種調整大小會如何引入不必要的拉伸!!!

### 將utilities放在一起
"""

batch_size = 64 #設定batch_size的值
padding_token = 99 #設定padding_token的值
image_width = 128 #設定image_width的值
image_height = 32 #設定image_width的值

def preprocess_image(image_path, img_size=(image_width, image_height)):#設定一個函數 用來設定圖片`
    image = tf.io.read_file(image_path) #使用tf.io.read_file()函數來讀取文件
    image = tf.image.decode_png(image, 1) #使用tf.image.decode_png來解碼png格式
    image = distortion_free_resize(image, img_size) #調整圖片大小
    image = tf.cast(image, tf.float32) / 255.0 #執行類型轉換，將image轉成float32格式
    return image#回傳

def vectorize_label(label): #設定一個函數 用來設定標籤
    label = char_to_num(tf.strings.unicode_split(label, input_encoding="UTF-8"))#將字符轉換成數字(以UTF-8表示)
    length = tf.shape(label)[0] #獲取張量大小
    pad_amount = max_len - length#pad_amount的值為max_len減length
    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)#填充維度
    return label#回傳

def process_images_labels(image_path, label): #設定一個函數 用來回傳圖片和標籤
    image = preprocess_image(image_path)#讀取圖片
    label = vectorize_label(label)#將函數像量化
    return {"image": image, "label": label}#回傳

def prepare_dataset(image_paths, labels): #設定一個函數 用來準備圖片路徑和標籤
    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map( #給列表或張量對特徵進行切割 .map(對指定序列做處理)
        process_images_labels, num_parallel_calls=AUTOTUNE
    )
    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)#回傳

"""## 準備 `tf.data.Dataset` 對象"""

train_ds = prepare_dataset(train_img_paths, train_labels_cleaned) #prepare_dataset將數據分割成塊，為模型訓練做準備
validation_ds = prepare_dataset(validation_img_paths, validation_labels_cleaned)
test_ds = prepare_dataset(test_img_paths, test_labels_cleaned)

"""## 可視化一些樣本"""

for data in train_ds.take(1):#進行迴圈
    images, labels = data["image"], data["label"]#設定image及label的存放位置
    _, ax = plt.subplots(4, 4, figsize=(15, 8))#對圖像編碼4進行連續畫圖
    for i in range(16):#進行迴圈
        img = images[i]#定義img
        img = tf.image.flip_left_right(img)#水平翻轉圖像
        img = tf.transpose(img, perm=[1, 0, 2])#進行轉置
        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)#將資料進行剪切並轉換格式
        img = img[:, :, 0]#對img的多段陣列進行切割

        # Gather indices where label!= padding_token.
        label = labels[i]#設定label的值
        indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))#獲取緯度上的資料
        # Convert to string.
        label = tf.strings.reduce_join(num_to_char(indices))#將所有的字符串連接
        label = label.numpy().decode("utf-8")#將資料型態轉成utf-8

        ax[i // 4, i % 4].imshow(img, cmap="gray")#繪製圖片
        ax[i // 4, i % 4].set_title(label)#設定標題
        ax[i // 4, i % 4].axis("off")#關閉座標軸
plt.show()#印出

"""原始圖像的內容盡可能地保留並進行了相應的填充。

## 模型
"""

class CTCLayer(keras.layers.Layer):#有多個輸出、輸入張量的層,這是所有圖層繼承的定義-CTCLayer
    def __init__(self, name=None): #初始化
        super().__init__(name=name)
        self.loss_fn = keras.backend.ctc_batch_cost

    def call(self, y_true, y_pred): #向前傳導
        batch_len = tf.cast(tf.shape(y_true)[0], dtype="int64")
        input_length = tf.cast(tf.shape(y_pred)[1], dtype="int64")
        label_length = tf.cast(tf.shape(y_true)[1], dtype="int64")

        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype="int64")
        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype="int64")
        loss = self.loss_fn(y_true, y_pred, input_length, label_length)
        self.add_loss(loss)

        # At test time, just return the computed predictions.
        return y_pred

def build_model(): #導入模型
    # Inputs to the model
    input_img = keras.Input(shape=(image_width, image_height, 1), name="image") #放入圖片
    labels = keras.layers.Input(name="label", shape=(None,))#放入標籤

    # First conv block.
    x = keras.layers.Conv2D( #卷積函數Conv2D
        32, #輸出空間的維數（即卷積中輸出過濾器的數量）
        (3, 3), #更新的移動步數。卷積在圖像上的移動幅度
        activation="relu",#使用的激活函數
        kernel_initializer="he_normal",#矩陣的初始化器
        padding="same",#左/右或上/下均勻地填充
        name="Conv1",
    )(input_img)#加載圖片
    x = keras.layers.MaxPooling2D((2, 2), name="pool1")(x)#定義最大池化

    # Second conv block.
    x = keras.layers.Conv2D(#設定捲積函數
        64,
        (3, 3),
        activation="relu",
        kernel_initializer="he_normal",
        padding="same",
        name="Conv2",
    )(x)
    x = keras.layers.MaxPooling2D((2, 2), name="pool2")(x)#定義最大池化

    # We have used two max pool with pool size and strides 2.
    # Hence, downsampled feature maps are 4x smaller. The number of
    # filters in the last layer is 64. Reshape accordingly before
    # passing the output to the RNN part of the model.
    new_shape = ((image_width // 4), (image_height // 4) * 64)#定義圖片大小
    x = keras.layers.Reshape(target_shape=new_shape, name="reshape")(x)#完成不同維度的對接
    x = keras.layers.Dense(64, activation="relu", name="dense1")(x)#定義網路層
    x = keras.layers.Dropout(0.2)(x)#防止過度擬合

    # RNNs.
    x = keras.layers.Bidirectional(#定義RNN類型的雙向構造
        keras.layers.LSTM(128, return_sequences=True, dropout=0.25)
    )(x)
    x = keras.layers.Bidirectional(#定義RNN類型的雙向構造
        keras.layers.LSTM(64, return_sequences=True, dropout=0.25)
    )(x)

    # +2 is to account for the two special tokens introduced by the CTC loss.
    # The recommendation comes here: https://git.io/J0eXP.
    x = keras.layers.Dense(#定義網路層
        len(char_to_num.get_vocabulary()) + 2, activation="softmax", name="dense2"
    )(x)

    # Add CTC layer for calculating CTC loss at each step.
    output = CTCLayer(name="ctc_loss")(labels, x)#定義output

    # Define the model.
    model = keras.models.Model(#建立模型
        inputs=[input_img, labels], outputs=output, name="handwriting_recognizer"
    )
    # Optimizer.
    opt = keras.optimizers.Adam()#建立優化器
    # Compile the model and return.
    model.compile(optimizer=opt)#配置訓練方法
    return model#回傳
# Get the model.
model = build_model()#導入模型
model.summary()#顯示目前網路架構

"""## 評價指標

編輯距離是評估OCR模型時使用最廣泛的指標。我們將實現它並將其用作回調來監控我們的模型。

為了方便起見，我們首先將驗證圖像及其標籤分開。
"""

validation_images = []#定義validation_images
validation_labels = []#定義validation_labels

for batch in validation_ds:#進行迴圈
    validation_images.append(batch["image"])#添加資料在validation_images的最尾端
    validation_labels.append(batch["label"])#添加資料在validation_labels的最尾端

"""創建一個回調來監控編輯距離。"""

def calculate_edit_distance(labels, predictions):#定義函數
    # Get a single batch and convert its labels to sparse tensors.
    saprse_labels = tf.cast(tf.sparse.from_dense(labels), dtype=tf.int64)#數據類型轉換

    # Make predictions and convert them to sparse tensors.
    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]#定義input_len
    predictions_decoded = keras.backend.ctc_decode(#進行解碼
        predictions, input_length=input_len, greedy=True
    )[0][0][:, :max_len]
    sparse_predictions = tf.cast(#數據類型轉換
        tf.sparse.from_dense(predictions_decoded), dtype=tf.int64
    )

    # Compute individual edit distances and average them out.
    edit_distances = tf.edit_distance(#計算Levenshtein的距離
        sparse_predictions, saprse_labels, normalize=False
    )
    return tf.reduce_mean(edit_distances)#回傳
class EditDistanceCallback(keras.callbacks.Callback): #用來追蹤到模型訓練和推理生命週期的各個階段
    def __init__(self, pred_model):#定義函數
        super().__init__()#繼承
        self.prediction_model = pred_model#定義self.prediction_model

    def on_epoch_end(self, epoch, logs=None):#定義一個函數
        edit_distances = []#定義空陣列

        for i in range(len(validation_images)):#設定迴圈
            labels = validation_labels[i]#定義labels
            predictions = self.prediction_model.predict(validation_images[i])#訓練後返回預測結果
            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())#添加值到列表最後

        print(#印出
            f"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}"
        )

"""## 訓練"""

epochs = 10 #定義epochs
 # To get good results this should be at least 50.

model = build_model()#建立model
prediction_model = keras.models.Model(#建立預測模型
    model.get_layer(name="image").input, model.get_layer(name="dense2").output
)
edit_distance_callback = EditDistanceCallback(prediction_model)#回傳一個轉到另一個的最少操作次數(又稱萊文斯坦距離(Levenshtein))

# Train the model.
history = model.fit(#執行訓練過程
    train_ds,
    validation_data=validation_ds,
    epochs=epochs,
    callbacks=[edit_distance_callback],
)

"""## 推理"""

# A utility function to decode the output of the network.
def decode_batch_predictions(pred):#定義函式
    input_len = np.ones(pred.shape[0]) * pred.shape[1]#讀取第一陣列長度後,生成一個用1填充的等長陣列*第二陣列長度
    # Use greedy search. For complex tasks, you can use beam search.
    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][
        :, :max_len
    ] #使用貪心搜索
    # Iterate over the results and get back the text.
    output_text = []#返回文本
    for res in results: #進行迴圈 遍歷輸出結果
        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))
        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode("utf-8")
        output_text.append(res)
    return output_text #回傳文本


#  Let's check results on some test samples.
for batch in test_ds.take(1): #取樣本來檢查
    batch_images = batch["image"]
    _, ax = plt.subplots(4, 4, figsize=(15, 8))

    preds = prediction_model.predict(batch_images)#預測的結果
    pred_texts = decode_batch_predictions(preds)#預測後傳回的文本

    for i in range(16): #讀取預測圖片各項數據 
        img = batch_images[i]#讀取圖片
        img = tf.image.flip_left_right(img)#水平翻轉圖像
        img = tf.transpose(img, perm=[1, 0, 2])#進行轉置
        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)#將資料進行剪切並轉換格式
        img = img[:, :, 0]#對img的多段陣列進行切割
        #製作顯示結果
        title = f"Prediction: {pred_texts[i]}"
        ax[i // 4, i % 4].imshow(img, cmap="gray")#顯示灰階圖片 這裡都顯示4張為一行
        ax[i // 4, i % 4].set_title(title)#設定標題
        ax[i // 4, i % 4].axis("off")#關閉座標軸顯示
plt.show()#印出

"""為了獲得更好的結果，模型應該至少訓練50個週期。"""